---
title: "Assignment 5 - Meta-analysis of pitch in schizophrenia"
author: "Josephine Hillebrand Hansen"
date: "3/7/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Building on the shoulders of giants: meta-analysis

## Questions to be answered

1. What is the current evidence for distinctive patterns of pitch mean and pitch sd in schizophrenia? Report how many papers report quantitative estimates, your method to analyze them, the estimated effect size of the difference (mean effect size and standard error for pitch mean, same for pitch sd) and forest plots representing it. 

2. Do the results match your own analysis from Assignment 3? If you add your results to the meta-analysis, do the estimated effect sizes change? Report the new estimates and the new forest plots.
- extract effect size from the data. SImplest way: scale data and report the beta as yi. standard deviation of effect = variability of diagnosis and square that
old data, old model, summary, standarddised beta = yi, squared SD = vi
comment on whether meta analysis changes

3. Assess the quality of the literature: report and comment on heterogeneity of the studies (tau, I2), on publication bias (funnel plot), and on influential studies.

## Tips on the process to follow:

- Download the data on all published articles analyzing pitch in schizophrenia: https://www.dropbox.com/s/pmgw8wzc308so1p/Data.csv?dl=0
```{r}
data = read.csv("Data.csv", sep = ";")
```


- Following the procedure in the slides calculate effect size and standard error of the effect size per each study. N.B. we focus on pitch mean and pitch standard deviation. #Do it for pitch mean and pitchSD
 . first try using lmer (to connect to what you know of mixed effects models)
 . then use rma() (to get some juicy additional statistics)

```{r}
library(pacman)
library(metafor)

#Escalc
PitchMean = escalc("SMD",
                   n1i = SampleSizeSchizo,
                   n2i = SampleSizeContros,
                   m1i = PitchMeanSchizo,
                   m2i = PitchMeanControls,
                   sd1i = PitchMeanSchizoSD,
                   sd2i = PitchMeanControlsSD,
                   data = data)

PitchSD = escalc("SMD",
                   n1i = SampleSizeSchizo,
                   n2i = SampleSizeContros,
                   m1i = PitchSDSchizo,
                   m2i = PitchSDControls,
                   sd1i = PitchSDSchizoSD,
                   sd2i = PitchSDControlsSD,
                   data = data)


#Predict by using lmer
library(lmerTest)

modelMean = lmerTest::lmer(yi ~ 1 + (1|Article), weights = 1/vi, data = PitchMean, control = lmerControl(check.nobs.vs.nlev = "ignore", check.nobs.vs.nRE = "ignore"))

modelPitch = lmerTest::lmer(yi ~ 1 + (1|Article), weights = 1/vi, data = PitchSD, control = lmerControl(check.nobs.vs.nlev = "ignore", check.nobs.vs.nRE = "ignore"))


#Using RMA for meta-analysis optimization
resMean = rma(yi, vi, data = PitchMean, slab = Article)

resSD = rma(yi, vi, data = PitchSD, slab = Article)

```


- Build a forest plot of the results (forest(model))
 
```{r}
#Forest plot mean
forest(resMean)

forest(resSD)


```

- Go back to Assignment 3, add your own study to the data table, and re-run meta-analysis. Do the results change?

```{r}
#Read data from assignment 3 into R
dataAssign3 = read.csv("C:/Users/hille/OneDrive/Cognitive Science at Aarhus University/2017 - Experimental Methods 3/assignments/Assignment-3/Assignment-3/dataExtractSchizo.csv")

#Controls
#for mean---------------------------------------
# Calculate mean and SD mean
mean(dataAssign3$mean[dataAssign3$diagnosis == "0"])
sd(dataAssign3$mean[dataAssign3$diagnosis == "0"])

#For SD--------------------------------------
mean(dataAssign3$stdDev[dataAssign3$diagnosis == "0"])
sd(dataAssign3$stdDev[dataAssign3$diagnosis == "0"])

#Schizo
# Calculate mean and SD mean
mean(dataAssign3$mean[dataAssign3$diagnosis == "1"])
sd(dataAssign3$mean[dataAssign3$diagnosis == "1"])

#For SD--------------------------------------
mean(dataAssign3$stdDev[dataAssign3$diagnosis == "1"])
sd(dataAssign3$stdDev[dataAssign3$diagnosis == "1"])


sCon = length(unique(dataAssign3$participant[dataAssign3$diagnosis == "0"]))

sSchi = length(unique(dataAssign3$participant[dataAssign3$diagnosis == "1"]))

#Add
dataMine = data.frame("Article" = "MyData", "Year" = NA, "SampleSizeSchizo" = sSchi, "SampleSizeContros" = sCon, "PitchMeanControls" = 149.0399, "PitchMeanControlsSD" = 55.38506, "PitchMeanSchizo" = 141.0266, "PitchMeanSchizoSD" = 49.09909, "PitchSDControls" = 22.75408, "PitchSDControlsSD" = 32.83777, "PitchSDSchizo" = 25.78532, "PitchSDSchizoSD" = 18.59616)


DataNew = rbind(data, dataMine)


#Escalc
PitchMeanNew = escalc("SMD",
                   n1i = SampleSizeSchizo,
                   n2i = SampleSizeContros,
                   m1i = PitchMeanSchizo,
                   m2i = PitchMeanControls,
                   sd1i = PitchMeanSchizoSD,
                   sd2i = PitchMeanControlsSD,
                   data = DataNew)

PitchSDNew = escalc("SMD",
                   n1i = SampleSizeSchizo,
                   n2i = SampleSizeContros,
                   m1i = PitchSDSchizo,
                   m2i = PitchSDControls,
                   sd1i = PitchSDSchizoSD,
                   sd2i = PitchSDControlsSD,
                   data = DataNew)


#Using RMA for meta-analysis optimization
resMeanNew = rma(yi, vi, data = PitchMeanNew, slab = Article)

resSDNew = rma(yi, vi, data = PitchSDNew, slab = Article)


#Forest plots
forest(resMeanNew)

forest(resSDNew)


```


- Now look at the output of rma() and check tau and I2

```{r}
#Funnel plot for publication bias
funnel(resMeanNew, main = "Random-Effects Model", xlab = "Standardized Mean Differences")
regtest(resMeanNew)
ranktest(resMeanNew)

funnel(resSDNew, main = "Random-Effects Model", xlab = "Standardized Mean Differences")
regtest(resSDNew)
ranktest(resSDNew)
#Influencial studies


#Influential studies
#Mean
infMean = influence(resMeanNew)
print(infMean)
plot(infMean)


#SD
infSD = influence(resSDNew)
print(infSD)
plot(infSD)

```

